{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 Count Vectorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzc6XyzQ7emeLHJ58A1Ju9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandipanpaul21/NLP-using-Python/blob/master/08_Count_Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmtW8zlxJJGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count Vectorization (AKA One-Hot Encoding)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW_9E3D7SViJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIgsp6wQSWvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "726ccbf3-7f65-4b2f-9461-186917c97d2b"
      },
      "source": [
        "# CountVectorizer\n",
        "\n",
        "# To create a Count Vectorizer, we simply need to instantiate one.\n",
        "# There are special parameters we can set here when making the vectorizer, but\n",
        "# for the most basic example, it is not needed.\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBs_R91vSe9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a13d9a81-215d-46cf-aad6-77c37ec218fb"
      },
      "source": [
        "# For our text, we are going to take some text\n",
        "\n",
        "sample_text = [\"One of the most basic ways we can numerically represent words \"\n",
        "               \"is through the one-hot encoding method also sometimes called \"\n",
        "               \"count vectorizing.\"]\n",
        "sample_text\n",
        "\n",
        "# Two words are repeated - 'One' and 'The'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['One of the most basic ways we can numerically represent words is through the one-hot encoding method also sometimes called count vectorizing.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-eSk1oSq0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "4009b7ec-1758-4697-aab8-ad502fbcb238"
      },
      "source": [
        "# To actually create the vectorizer, we simply need to call fit on the text\n",
        "# data that we wish to fix\n",
        "vectorizer.fit(sample_text)\n",
        "\n",
        "# Now, we can inspect how our vectorizer vectorized the text\n",
        "# This will print out a list of words used, and their index in the vectors\n",
        "print('Vocabulary Index: ')\n",
        "print(vectorizer.vocabulary_)\n",
        "\n",
        "# Position of 'One' : 12 & 'The' : 15\n",
        "# Note : Position starts from 0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Index: \n",
            "{'one': 12, 'of': 11, 'the': 15, 'most': 9, 'basic': 1, 'ways': 18, 'we': 19, 'can': 3, 'numerically': 10, 'represent': 13, 'words': 20, 'is': 7, 'through': 16, 'hot': 6, 'encoding': 5, 'method': 8, 'also': 0, 'sometimes': 14, 'called': 2, 'count': 4, 'vectorizing': 17}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgMHj4zhSxWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b39bbb49-3d61-4829-8c4c-9009cb2e39f3"
      },
      "source": [
        "# If we would like to actually create a vector, we can do so by passing the\n",
        "# text into the vectorizer to get back counts\n",
        "vector = vectorizer.transform(sample_text)\n",
        "\n",
        "# Our final vector:\n",
        "print('Full vector: ')\n",
        "print(vector.toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full vector: \n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZtoUfVPTAbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4ffd3188-0c30-493b-aa72-3124c24afa19"
      },
      "source": [
        "# Or if we wanted to get the vector for one word:\n",
        "# Position of 'Hot' word: 6\n",
        "print(\"'Hot' word vector: \")\n",
        "print(vectorizer.transform(['Hot']).toarray())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Hot' word vector: \n",
            "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMYBTxUXTUnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3849e8a0-8ab5-416d-9ce0-27435f836a18"
      },
      "source": [
        "# Or if we wanted to get multiple vectors at once to build matrices\n",
        "print('Hot and one: ')\n",
        "print(vectorizer.transform(['hot', 'one']).toarray())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hot and one: \n",
            "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsyGToe4TZDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d3b6b4b-34a3-404a-c243-63127c5d3e30"
      },
      "source": [
        "# We could also do the whole thing at once with the fit_transform method:\n",
        "print('Whole Method at Once:')\n",
        "new_text = ['Today is the day that I do the thing today, today']\n",
        "new_vectorizer = CountVectorizer()\n",
        "print(new_vectorizer.fit_transform(new_text).toarray())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Whole Method at Once:\n",
            "[[1 1 1 1 2 1 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mboUGnp7TdI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82760763-ba09-49d8-de57-5e4f27e80476"
      },
      "source": [
        "# Using It on Real Data:\n",
        "\n",
        "# So letâ€™s use it on some real data! \n",
        "# We will check out the 20 News Group dataset that comes with scikit-learn.\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create our vectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Let's fetch all the possible text data\n",
        "newsgroups_data = fetch_20newsgroups()\n",
        "\n",
        "# Why not inspect a sample of the text data?\n",
        "print('Sample 0: ')\n",
        "print(newsgroups_data.data[0])\n",
        "print()\n",
        "\n",
        "# Create the vectorizer\n",
        "vectorizer.fit(newsgroups_data.data)\n",
        "\n",
        "# Converting our first sample into a vector\n",
        "v0 = vectorizer.transform([newsgroups_data.data[0]]).toarray()[0]\n",
        "print('Sample 0 (vectorized): ')\n",
        "print(v0)\n",
        "print()\n",
        "\n",
        "# It's too big to even see...\n",
        "# What's the length?\n",
        "print('Sample 0 (vectorized) length: ')\n",
        "print(len(v0))\n",
        "print()\n",
        "\n",
        "# How many words does it have?\n",
        "print('Sample 0 (vectorized) sum: ')\n",
        "print(np.sum(v0))\n",
        "print()\n",
        "\n",
        "# What if we wanted to go back to the source?\n",
        "print('To the source:')\n",
        "print(vectorizer.inverse_transform(v0))\n",
        "print()\n",
        "\n",
        "# So all this data has a lot of extra garbage... Why not strip it away?\n",
        "newsgroups_data = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Why not inspect a sample of the text data?\n",
        "print('Sample 0: ')\n",
        "print(newsgroups_data.data[0])\n",
        "print()\n",
        "\n",
        "# Create the vectorizer\n",
        "vectorizer.fit(newsgroups_data.data)\n",
        "\n",
        "# Converting our first sample into a vector\n",
        "v0 = vectorizer.transform([newsgroups_data.data[0]]).toarray()[0]\n",
        "print('Sample 0 (vectorized): ')\n",
        "print(v0)\n",
        "print()\n",
        "\n",
        "# It's too big to even see...\n",
        "# What's the length?\n",
        "print('Sample 0 (vectorized) length: ')\n",
        "print(len(v0))\n",
        "print()\n",
        "\n",
        "# How many words does it have?\n",
        "print('Sample 0 (vectorized) sum: ')\n",
        "print(np.sum(v0))\n",
        "print()\n",
        "\n",
        "# What if we wanted to go back to the source?\n",
        "print('To the source:')\n",
        "print(vectorizer.inverse_transform(v0))\n",
        "print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 0: \n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sample 0 (vectorized): \n",
            "[0 0 0 ... 0 0 0]\n",
            "\n",
            "Sample 0 (vectorized) length: \n",
            "130107\n",
            "\n",
            "Sample 0 (vectorized) sum: \n",
            "122\n",
            "\n",
            "To the source:\n",
            "[array(['15', '60s', '70s', 'addition', 'all', 'anyone', 'be', 'body',\n",
            "       'bricklin', 'brought', 'bumper', 'by', 'called', 'can', 'car',\n",
            "       'college', 'could', 'day', 'door', 'doors', 'early', 'edu',\n",
            "       'engine', 'enlighten', 'from', 'front', 'funky', 'have', 'history',\n",
            "       'host', 'if', 'il', 'in', 'info', 'is', 'it', 'know', 'late',\n",
            "       'lerxst', 'lines', 'looked', 'looking', 'made', 'mail', 'maryland',\n",
            "       'me', 'model', 'my', 'name', 'neighborhood', 'nntp', 'of', 'on',\n",
            "       'or', 'organization', 'other', 'out', 'park', 'please', 'posting',\n",
            "       'production', 'rac3', 'really', 'rest', 'saw', 'separate', 'small',\n",
            "       'specs', 'sports', 'subject', 'tellme', 'thanks', 'the', 'there',\n",
            "       'thing', 'this', 'to', 'umd', 'university', 'wam', 'was', 'were',\n",
            "       'what', 'whatever', 'where', 'wondering', 'years', 'you', 'your'],\n",
            "      dtype='<U180')]\n",
            "\n",
            "Sample 0: \n",
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Sample 0 (vectorized): \n",
            "[0 0 0 ... 0 0 0]\n",
            "\n",
            "Sample 0 (vectorized) length: \n",
            "101631\n",
            "\n",
            "Sample 0 (vectorized) sum: \n",
            "85\n",
            "\n",
            "To the source:\n",
            "[array(['60s', '70s', 'addition', 'all', 'anyone', 'be', 'body',\n",
            "       'bricklin', 'bumper', 'called', 'can', 'car', 'could', 'day',\n",
            "       'door', 'doors', 'early', 'engine', 'enlighten', 'from', 'front',\n",
            "       'funky', 'have', 'history', 'if', 'in', 'info', 'is', 'it', 'know',\n",
            "       'late', 'looked', 'looking', 'made', 'mail', 'me', 'model', 'name',\n",
            "       'of', 'on', 'or', 'other', 'out', 'please', 'production', 'really',\n",
            "       'rest', 'saw', 'separate', 'small', 'specs', 'sports', 'tellme',\n",
            "       'the', 'there', 'this', 'to', 'was', 'were', 'whatever', 'where',\n",
            "       'wondering', 'years', 'you'], dtype='<U81')]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L1il9RGXRIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}