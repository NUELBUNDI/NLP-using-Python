## NLP-using-Python

Welcome to a Natural Language Processing series, using the Natural Language Toolkit, or NLTK, module with Python

### 01 Tokenizing Word and Sentence 
#### Token
  * Each "entity" that is a part of whatever was split up based on rules. 
  * For examples, each word is a token when a sentence is "tokenized" into words.
  * Each sentence can also be a token, if you tokenized the sentences out of a paragraph.

### 02 Stop Words
 * Stop words as words that just contain no meaning, we want to remove them.
 * Words like we, she, is, a etc.

### 03 Stemming
 * The idea of stemming is a sort of normalizing method.
 * Many variations of words carry the same meaning, other than when tense is involved.
 * The reason why we stem is to shorten the lookup, and normalize sentences.
